{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n",
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, ModelSummary\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from src.datasets import (LMDataset, CausalLMDataset, CausalLMPredictionDataset, MaskedLMDataset,\n",
    "                          MaskedLMPredictionDataset, PaddingCollateFn)\n",
    "from src.metrics import compute_metrics\n",
    "from src.models import RNN, BERT4Rec, SASRec\n",
    "from src.modules import SeqRec, SeqRecWithSampling\n",
    "from src.postprocess import preds2recs\n",
    "from src.preprocess import add_time_idx\n",
    "from src.unbiased_metrics import get_metrics, hr, mrr, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_COL = 'item_id'\n",
    "RELEVANCE_THRESHOLD = 3.5\n",
    "RELEVANCE_COL = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/ml-1m/train.csv')\n",
    "test = pd.read_csv('../data/ml-1m/test.csv')\n",
    "val_1 = pd.read_csv('../data/ml-1m/val_1.csv')\n",
    "val_2 = pd.read_csv('../data/ml-1m/val_2.csv')\n",
    "test_users_history = pd.read_csv('../data/ml-1m/test_users_history.csv')\n",
    "val_users_history_1 = pd.read_csv('../data/ml-1m/val_users_history_1.csv')\n",
    "val_users_history_2 = pd.read_csv('../data/ml-1m/val_users_history_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.item_id = train.item_id * 2\n",
    "val_users_history_1.item_id = val_users_history_1.item_id * 2\n",
    "val_users_history_2.item_id = val_users_history_2.item_id * 2\n",
    "test_users_history.item_id = test_users_history.item_id * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[RELEVANCE_COL] < RELEVANCE_THRESHOLD, 'item_id'] -= 1\n",
    "val_users_history_1.loc[val_users_history_1[RELEVANCE_COL] < RELEVANCE_THRESHOLD, 'item_id'] -= 1\n",
    "val_users_history_2.loc[val_users_history_2[RELEVANCE_COL] < RELEVANCE_THRESHOLD, 'item_id'] -= 1\n",
    "test_users_history.loc[test_users_history[RELEVANCE_COL] < RELEVANCE_THRESHOLD, 'item_id'] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200\n",
    "\n",
    "VALIDATION_SIZE = 10000\n",
    "# VALIDATION_SIZE = None\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class NegFeedbackDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, max_length=128,\n",
    "                 user_col='user_id', item_col=ITEM_COL, time_col='time_idx',\n",
    "                 duration_col=RELEVANCE_COL, positive_labels=True,\n",
    "                 duration_threshold=3.5):\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "        self.time_col = time_col\n",
    "        self.duration_col = duration_col\n",
    "        self.positive_labels = positive_labels\n",
    "        self.duration_threshold = duration_threshold\n",
    "\n",
    "        df = df.sort_values(time_col)\n",
    "        self.items = df.groupby(user_col)[item_col].agg(list).to_dict()\n",
    "        self.duration = df.groupby(user_col)[duration_col].agg(list).to_dict()\n",
    "        self.user_ids = list(self.items.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        item_sequence = self.items[self.user_ids[idx]]\n",
    "        duration_sequence = self.duration[self.user_ids[idx]]\n",
    "\n",
    "        if len(item_sequence) > self.max_length + 1:\n",
    "            item_sequence = item_sequence[-self.max_length - 1:]\n",
    "            duration_sequence = duration_sequence[-self.max_length - 1:]\n",
    "\n",
    "        input_ids = np.array(item_sequence[:-1])\n",
    "        duration = np.array(duration_sequence[:-1])\n",
    "        labels = np.array(item_sequence[1:])\n",
    "        \n",
    "        if self.positive_labels:\n",
    "            labels = labels.astype(float)\n",
    "            labels[np.array(duration_sequence[1:]) < self.duration_threshold] = np.nan\n",
    "            labels = pd.Series(labels).fillna(method='bfill').values\n",
    "\n",
    "            input_ids = input_ids[~np.isnan(labels)]\n",
    "            duration = duration[~np.isnan(labels)]\n",
    "            labels = labels[~np.isnan(labels)]\n",
    "            labels = labels.astype(int)\n",
    "            \n",
    "            # convert to binary\n",
    "            #feedback = (duration >= self.duration_threshold).astype(int) + 1\n",
    "\n",
    "        return {'input_ids': input_ids, 'labels': labels}\n",
    "\n",
    "class NegFeedbackPredictionDataset(NegFeedbackDataset):\n",
    "\n",
    "    def __init__(self, df, max_length=128, validation_mode=False,\n",
    "                 user_col='test_user_idx', item_col=ITEM_COL,\n",
    "                 time_col='time_idx', duration_col=RELEVANCE_COL,\n",
    "                 positive_labels=True, duration_threshold=30):\n",
    "\n",
    "        super().__init__(df, max_length=max_length,\n",
    "                         user_col=user_col, item_col=item_col, time_col=time_col,\n",
    "                         duration_col=duration_col, positive_labels=positive_labels,\n",
    "                         duration_threshold=duration_threshold)\n",
    "\n",
    "        self.validation_mode = validation_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        user_id = self.user_ids[idx]\n",
    "        item_sequence = self.items[user_id]\n",
    "        duration_sequence = self.duration[self.user_ids[idx]]\n",
    "\n",
    "        if self.validation_mode:\n",
    "            target = item_sequence[-1]\n",
    "            input_ids = np.array(item_sequence[-self.max_length-1:-1])\n",
    "            duration = np.array(duration_sequence[-self.max_length-1:-1])\n",
    "            item_sequence = item_sequence[:-1]\n",
    "            # convert to binary\n",
    "            #feedback = (duration >= self.duration_threshold).astype(int) + 1\n",
    "\n",
    "            return {'input_ids': input_ids, 'user_id': user_id,\n",
    "                    'full_history': item_sequence, 'target': target,\n",
    "                    }\n",
    "        else:\n",
    "            input_ids = np.array(item_sequence[-self.max_length:])\n",
    "            duration = np.array(duration_sequence[-self.max_length:])\n",
    "            # convert to binary\n",
    "            #feedback = (duration >= self.duration_threshold).astype(int) + 1\n",
    "\n",
    "            return {'input_ids': input_ids, 'user_id': user_id,\n",
    "                    'full_history': item_sequence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegFeedbackDataset(LMDataset):\n",
    "\n",
    "    def __init__(self, df, max_length=200, num_negatives=None, full_negative_sampling=True,\n",
    "                 user_col='user_id', item_col=ITEM_COL, time_col='time_idx',\n",
    "                 relevance_col=RELEVANCE_COL, positive_labels=True,\n",
    "                 relevance_threshold=3.5):\n",
    "\n",
    "        super().__init__(df, max_length, num_negatives, full_negative_sampling,\n",
    "                         user_col, item_col, time_col)\n",
    "        #self.num_negatives = num_negatives\n",
    "        #self.max_length = max_length\n",
    "        #self.user_col = user_col\n",
    "        #self.item_col = item_col\n",
    "        #self.time_col = time_col\n",
    "        self.relevance_col = relevance_col\n",
    "        self.positive_labels = positive_labels\n",
    "        self.relevance_threshold = relevance_threshold\n",
    "\n",
    "        df = df.sort_values(time_col)\n",
    "        self.items = df.groupby(user_col)[item_col].agg(list).to_dict()\n",
    "        self.relevance = df.groupby(user_col)[relevance_col].agg(list).to_dict()\n",
    "        self.user_ids = list(self.items.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        item_sequence = self.items[self.user_ids[idx]]\n",
    "        relevance_sequence = self.relevance[self.user_ids[idx]]\n",
    "\n",
    "        if len(item_sequence) > self.max_length + 1:\n",
    "            item_sequence = item_sequence[-self.max_length - 1:]\n",
    "            relevance_sequence = relevance_sequence[-self.max_length - 1:]\n",
    "\n",
    "        input_ids = np.array(item_sequence[:-1])\n",
    "        relevance = np.array(relevance_sequence[:-1])\n",
    "        labels = np.array(item_sequence[1:])\n",
    "        \n",
    "        if self.positive_labels:\n",
    "            labels = labels.astype(float)\n",
    "            labels[np.array(relevance_sequence[1:]) < self.relevance_threshold] = np.nan\n",
    "            labels = pd.Series(labels).fillna(method='bfill').values\n",
    "\n",
    "            input_ids = input_ids[~np.isnan(labels)]\n",
    "            relevance = relevance[~np.isnan(labels)]\n",
    "            labels = labels[~np.isnan(labels)]\n",
    "            labels = labels.astype(int)\n",
    "            \n",
    "            # convert to binary\n",
    "            #feedback = (relevance >= self.relevance_threshold).astype(int) + 1\n",
    "        if self.num_negatives:\n",
    "            negatives = self.sample_negatives(item_sequence)\n",
    "            return {'input_ids': input_ids, 'labels': labels, 'negatives': negatives}\n",
    "        \n",
    "\n",
    "        return {'input_ids': input_ids, 'labels': labels}\n",
    "\n",
    "class NegFeedbackPredictionDataset(NegFeedbackDataset):\n",
    "\n",
    "    def __init__(self, df, max_length=200, validation_mode=False,\n",
    "                 user_col='test_user_idx', item_col=ITEM_COL,\n",
    "                 time_col='time_idx', relevance_col=RELEVANCE_COL,\n",
    "                 positive_labels=True, relevance_threshold=3.5):\n",
    "\n",
    "        super().__init__(df, max_length=max_length,\n",
    "                         user_col=user_col, item_col=item_col, time_col=time_col,\n",
    "                         relevance_col=relevance_col, positive_labels=positive_labels,\n",
    "                         relevance_threshold=relevance_threshold)\n",
    "\n",
    "        self.validation_mode = validation_mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        user_id = self.user_ids[idx]\n",
    "        item_sequence = self.items[user_id]\n",
    "        relevance_sequence = self.relevance[self.user_ids[idx]]\n",
    "\n",
    "        if self.validation_mode:\n",
    "            target = item_sequence[-1]\n",
    "            input_ids = np.array(item_sequence[-self.max_length-1:-1])\n",
    "            relevance = np.array(relevance_sequence[-self.max_length-1:-1])\n",
    "            item_sequence = item_sequence[:-1]\n",
    "            # convert to binary\n",
    "            #feedback = (relevance >= self.relevance_threshold).astype(int) + 1\n",
    "\n",
    "            return {'input_ids': input_ids, 'user_id': user_id,\n",
    "                    'full_history': item_sequence, 'target': target,\n",
    "                    }\n",
    "        else:\n",
    "            input_ids = np.array(item_sequence[-self.max_length:])\n",
    "            relevance = np.array(relevance_sequence[-self.max_length:])\n",
    "            # convert to binary\n",
    "            #feedback = (relevance >= self.relevance_threshold).astype(int) + 1\n",
    "\n",
    "            return {'input_ids': input_ids, 'user_id': user_id,\n",
    "                    'full_history': item_sequence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqRecNegFeedback(SeqRec):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.model(batch['input_ids'], batch['attention_mask'])\n",
    "        loss = self.compute_loss(outputs, batch)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def prediction_output(self, batch):\n",
    "        return self.model(batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "\n",
    "def get_eval_dataset_negative_feedback(validation_full, max_length, validation_size, relevance_col, relevance_threshold):\n",
    "    validation_users = validation_full.user_id.unique()\n",
    "\n",
    "    if validation_size and (validation_size < len(validation_users)):\n",
    "        validation_users = np.random.choice(validation_users, size=validation_size, replace=False)\n",
    "\n",
    "    eval_dataset = NegFeedbackPredictionDataset(\n",
    "        validation_full[validation_full.user_id.isin(validation_users)],\n",
    "        max_length=max_length,\n",
    "        user_col='test_user_idx',\n",
    "        validation_mode=True,\n",
    "        relevance_col=relevance_col,\n",
    "        relevance_threshold=relevance_threshold,\n",
    "    )\n",
    "    return eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (3651170672.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    return eval_dataset\u001b[0m\n\u001b[0m                       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''class SeqRecNegFeedback(SeqRec):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.model(batch['input_ids'], batch['attention_mask'])\n",
    "        loss = self.compute_loss(outputs, batch)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def prediction_output(self, batch):\n",
    "        return self.model(batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "\n",
    "def get_eval_dataset_negative_feedback(validation_full, max_length, validation_size, duration_col, duration_threshold):\n",
    "    validation_users = validation_full.user_id.unique()\n",
    "\n",
    "    if validation_size and (validation_size < len(validation_users)):\n",
    "        validation_users = np.random.choice(validation_users, size=validation_size, replace=False)\n",
    "\n",
    "    eval_dataset = NegFeedbackPredictionDataset(\n",
    "        validation_full[validation_full.user_id.isin(validation_users)],\n",
    "        max_length=max_length,\n",
    "        user_col='test_user_idx',\n",
    "        validation_mode=True,\n",
    "        duration_col=duration_col,\n",
    "        duration_threshold=duration_threshold,\n",
    "    )\n",
    "    return eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 2.88 s, total: 29.4 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = NegFeedbackDataset(train,\n",
    "                                   relevance_col=RELEVANCE_COL, \n",
    "                                   relevance_threshold=RELEVANCE_THRESHOLD, \n",
    "                                   max_length=MAX_LENGTH, \n",
    "                                   num_negatives=3000)\n",
    "val_1_dataset = get_eval_dataset_negative_feedback(val_users_history_1,\n",
    "                                                  max_length=MAX_LENGTH, \n",
    "                                                  validation_size=VALIDATION_SIZE,\n",
    "                                                  relevance_col=RELEVANCE_COL,\n",
    "                                                  relevance_threshold=RELEVANCE_THRESHOLD)\n",
    "\n",
    "val_2_dataset = get_eval_dataset_negative_feedback(val_users_history_2,\n",
    "                                                  max_length=MAX_LENGTH, \n",
    "                                                  validation_size=VALIDATION_SIZE,\n",
    "                                                  relevance_col=RELEVANCE_COL,\n",
    "                                                  relevance_threshold=RELEVANCE_THRESHOLD)\n",
    "test_dataset = get_eval_dataset_negative_feedback(test_users_history,\n",
    "                                                  max_length=MAX_LENGTH, \n",
    "                                                  validation_size=VALIDATION_SIZE,\n",
    "                                                  relevance_col=RELEVANCE_COL,\n",
    "                                                  relevance_threshold=RELEVANCE_THRESHOLD)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE,\n",
    "    shuffle=True, num_workers=NUM_WORKERS,\n",
    "    collate_fn=PaddingCollateFn()\n",
    ")\n",
    "val_1_loader = DataLoader(\n",
    "    val_1_dataset, batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, num_workers=NUM_WORKERS,\n",
    "    collate_fn=PaddingCollateFn()\n",
    ")\n",
    "val_2_loader = DataLoader(\n",
    "    val_2_dataset, batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, num_workers=NUM_WORKERS,\n",
    "    collate_fn=PaddingCollateFn()\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, num_workers=NUM_WORKERS,\n",
    "    collate_fn=PaddingCollateFn()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 200])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_1_loader))\n",
    "print(batch['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SASREC_CONFIG = {\n",
    "    'maxlen': 200,\n",
    "    'hidden_units': 64,\n",
    "    'num_blocks': 2,\n",
    "    'num_heads': 1,\n",
    "    'dropout_rate': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = train.item_id.max()\n",
    "add_head = True\n",
    "\n",
    "model = SASRec(item_num=item_count, add_head=add_head, **SASREC_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200, 7905])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(batch['input_ids'], batch['attention_mask'])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                       | Type       | Params\n",
      "----------------------------------------------------------\n",
      "0 | model                      | SASRec     | 569 K \n",
      "1 | model.item_emb             | Embedding  | 505 K \n",
      "2 | model.pos_emb              | Embedding  | 12.8 K\n",
      "3 | model.emb_dropout          | Dropout    | 0     \n",
      "4 | model.attention_layernorms | ModuleList | 256   \n",
      "5 | model.attention_layers     | ModuleList | 33.3 K\n",
      "6 | model.forward_layernorms   | ModuleList | 256   \n",
      "7 | model.forward_layers       | ModuleList | 16.6 K\n",
      "8 | model.last_layernorm       | LayerNorm  | 128   \n",
      "----------------------------------------------------------\n",
      "569 K     Trainable params\n",
      "0         Non-trainable params\n",
      "569 K     Total params\n",
      "2.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7168342d0424f8fbc0b2c0a6b207a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seqrec_module = SeqRecNegFeedback(model, lr=0.001, predict_top_k=200, filter_seen=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_ndcg\", mode=\"max\", patience=10, verbose=False)\n",
    "\n",
    "model_summary = ModelSummary(max_depth=2)\n",
    "checkpoint = ModelCheckpoint(save_top_k=1, monitor=\"val_ndcg\",\n",
    "                             mode=\"max\", save_weights_only=True)\n",
    "callbacks=[early_stopping, model_summary, checkpoint]\n",
    "\n",
    "trainer = pl.Trainer(callbacks=callbacks, enable_checkpointing=True,\n",
    "                     gpus=1, max_epochs=100)\n",
    "\n",
    "trainer.fit(model=seqrec_module,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_2_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqrec_module.load_state_dict(torch.load(checkpoint.best_model_path)['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c8b604813d4bd8a18aab6fffc0474c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 188it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76387752, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2180</td>\n",
       "      <td>6.803426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>6.694895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2466</td>\n",
       "      <td>6.442806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2484</td>\n",
       "      <td>6.222824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7248</td>\n",
       "      <td>6.159751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  prediction\n",
       "0        0     2180    6.803426\n",
       "1        0      220    6.694895\n",
       "2        0     2466    6.442806\n",
       "3        0     2484    6.222824\n",
       "4        0     7248    6.159751"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqrec_module.predict_top_k = test.item_id.nunique()\n",
    "preds = trainer.predict(model=seqrec_module, dataloaders=val_2_loader)\n",
    "\n",
    "preds_val = preds2recs(preds)\n",
    "print(preds_val.shape)\n",
    "preds_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdbec0200d24088b1634442ae2cbba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 188it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152775504, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7502</td>\n",
       "      <td>6.958642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7156</td>\n",
       "      <td>6.831086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7728</td>\n",
       "      <td>6.234657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6656</td>\n",
       "      <td>6.072198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6962</td>\n",
       "      <td>5.754722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  prediction\n",
       "0        0     7502    6.958642\n",
       "1        0     7156    6.831086\n",
       "2        0     7728    6.234657\n",
       "3        0     6656    6.072198\n",
       "4        0     6962    5.754722"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqrec_module.predict_top_k = test.item_id.nunique()\n",
    "preds = trainer.predict(model=seqrec_module, dataloaders=test_loader)\n",
    "\n",
    "preds_test = preds2recs(preds)\n",
    "print(preds_test.shape)\n",
    "preds_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4090740/4127184720.py:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  preds_test.loc[:, 'item_id'] /= 2\n"
     ]
    }
   ],
   "source": [
    "preds_test = preds_test[preds_test.item_id % 2 == 0]\n",
    "preds_test.loc[:, 'item_id'] /= 2\n",
    "preds_test = preds_test.groupby('user_id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4090740/696867218.py:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  preds_val.loc[:, 'item_id'] /= 2\n"
     ]
    }
   ],
   "source": [
    "preds_val = preds_val[preds_val.item_id % 2 == 0]\n",
    "preds_val.loc[:, 'item_id'] /= 2\n",
    "preds_val = preds_val.groupby('user_id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds_test.groupby('user_id').count().item_id < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = (preds_val\n",
    "              .rename(columns={'user_id': 'test_user_idx', 'item_id': 'pred_items'})\n",
    "              .groupby('test_user_idx')['pred_items']\n",
    "              .apply(list).reset_index()\n",
    "              .merge(val_2, on='test_user_idx', how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = (preds_test\n",
    "              .rename(columns={'user_id': 'test_user_idx', 'item_id': 'pred_items'})\n",
    "              .groupby('test_user_idx')['pred_items']\n",
    "              .apply(list).reset_index()\n",
    "              .merge(test, on='test_user_idx', how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df, beta = get_metrics(preds_test, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>HR</th>\n",
       "      <th>MRR</th>\n",
       "      <th>nDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biased</td>\n",
       "      <td>0.139302</td>\n",
       "      <td>0.049017</td>\n",
       "      <td>0.069879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbiased</td>\n",
       "      <td>0.219345</td>\n",
       "      <td>0.129060</td>\n",
       "      <td>0.127188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unbiased_feedback_sampling</td>\n",
       "      <td>0.675571</td>\n",
       "      <td>0.253271</td>\n",
       "      <td>0.087945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         type        HR       MRR      nDCG\n",
       "0                      Biased  0.139302  0.049017  0.069879\n",
       "1                    Unbiased  0.219345  0.129060  0.127188\n",
       "2  Unbiased_feedback_sampling  0.675571  0.253271  0.087945"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09299743475619497"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.unbiased_metrics import confusion_matrix_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_col = 'rating'\n",
    "relevance_threshold=3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_pos = preds_test[preds_test[relevance_col] >= relevance_threshold]\n",
    "preds_val_neg = preds_val[preds_val[relevance_col] < relevance_threshold]\n",
    "preds_val_pos = preds_val[preds_val[relevance_col] >= relevance_threshold]\n",
    "\n",
    "tp, fn = confusion_matrix_metrics(preds_val_pos, user_col, item_col)\n",
    "fp, tn = confusion_matrix_metrics(preds_val_neg, user_col, item_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6799846331156358"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13676402410755678"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_pos = preds_test[preds_test['rating'] >= 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.675571, 0.0014082339740911776)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr(preds_test_pos, beta=beta, sample_feedback=True, return_confidence_interval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.253271, 0.0010478673038056274)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr(preds_test_pos, beta=beta, sample_feedback=True, return_confidence_interval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.087945, 6.648713827063502e-05)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg(preds_test_pos, beta=beta, sample_feedback=True, return_confidence_interval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "veronika_env39",
   "language": "python",
   "name": "veronika_env39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
